{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rackcli - h4x^2 VCV Rack via command line\n",
    "\n",
    "This is a catchall for any h4x that don't yet fit somewhere else, a lab's lab so to speak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "rackcli_core imports:\n",
      "    hp(pixels) - convert pixels to hp\n",
      "    is_running('rack') - predicate for OS-level process running, default \"rack\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run rackcli_core.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint as pp\n",
    "from typing import *\n",
    "from hashlib import sha256\n",
    "from pathlib import Path\n",
    "from time import sleep\n",
    "import os, json, datetime, copy, mido, shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VCV Rack running from /Users/dirkleas/Desktop/h4x/_queue_/vcv/Rack -- fork FTW!!!\n"
     ]
    }
   ],
   "source": [
    "rackdir = '/Users/dirkleas/Desktop/h4x/_queue_/vcv/Rack'\n",
    "# rackdir = '/Users/dirkleas/Documents/Rack'\n",
    "catalog = json.load(open(rackdir + '/catalog.json'))\n",
    "catalog_partial = json.load(open(rackdir + '/catalog.partial.json'))\n",
    "print(f'VCV Rack running from {rackdir}' + (' -- fork FTW!!!' if rackdir.find('Doc') == -1 else ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First things first, lets create some catalog support infrastructure. In a perfect world, we'd be able to do everyting catalog related from a plugin module, all hands free. Unfortunately, since you can't instantiate plugins outside the main Rack thread, requiring a fork, here are some non-fork support functions relating to the catalog based around this catch-all data model stashed in `catalog.index.json`:\n",
    "\n",
    "```\n",
    "{\n",
    "    sep: SEPARATOR', # separator for PLUGIN composition\n",
    "    rackdir: DIR, catalog: FILENAME, timestamp: LAST_MOD_TIMESTAMP,\n",
    "    plugins: {PLUGIN: (INDEX, DIR_HASH)}, pluginCount: 99, # plugin slug, hash used to track plugin updates\n",
    "    modules: {MODULE: (INDEX, HASH)}, moduleCount: 99, # plugin<sep>module slugs, hash for screenshots filenames\n",
    "    iterator: [(PLUGIN_SLUG, VERSION, MODULE_SLUG)], # catalog.partial.json order\n",
    "    faults: [(PLUGIN_SLUG, VERSION, MODULE_SLUG)]\n",
    "}\n",
    "```\n",
    "\n",
    "The plugins and modules indexes can be used to grab a particular plugin/module quickly for targetetd processing. The iterator can be use for processing all the modules, and since it's an ordered list, handy for partial processing restarts (e.g. generating screenshots, patches across the module corpus, etc.). Finally, the plugin hash allows for identifying distribution changes allowing catalog maintenance on an as-needed basis -- the other option is to just look for the particular cataloging asset (e.g. screenshot, instance metadata, etc.).\n",
    "\n",
    "Further, this `catalog.index.json` can be used to minimize catalog processing by identifying plugins that have changed -- theoretically, evaluate either:\n",
    "\n",
    "1. file system changes\n",
    "1. plugin/module slug + plugin version changes\n",
    "\n",
    "The advatages of the first option is that 1) it guards against plugin developers failing to update version for each release, though it requires multiple filesystem hits for each plugin; and 2) it can be resolved without any Rack code. Maintaining a `catalog.index.json` as a simple list of plugin hashes will allow quick testing for changes -- simply convert to set/list and test for hash inclusion -- if it's there, nothing changed. `catalog.index.json` can be maintained by serializing on every catalog run, or on demand.\n",
    "\n",
    "While the following implementation is in python, a compatible c++ POC is availble via a `cstat` project pending integration into various `catalog()` implementations.\n",
    "\n",
    "Note: when running `indexer()` on a large pool of plugins, it's probable that segfaults might occur. To resolve, when a crash occurs do the following:\n",
    "\n",
    "1. review stacktrace to identify offending module\n",
    "1. create a patch with `DLwigglz r4xh4x` and the offending module and any previous offenders from this process\n",
    "1. generate `patch.json` via `DLwigglz r4xh4x` by clicking the `patch` button\n",
    "1. run `p2f` to generate `faults.json`\n",
    "\n",
    "These faulty modules will be omitted from the index `iterator` section, and added to a special `faults` section of the same format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "code_folding": [
     0,
     4,
     13
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def hash_plugin_module(ps: str, pv: str, ms: str) -> str:\n",
    "    'hash plugin slug/version, model slug'\n",
    "    return(sha256(str.encode('{}|{}|{}'.format(ps, pv, ms))).hexdigest())\n",
    "\n",
    "def hash_plugin_files(plugin_dir: str) -> str:\n",
    "    'hash based on recursive glob on formtted stat m_times | cocatenated or None if invalid'\n",
    "    files = sorted([p for p in list(Path(plugin_dir).glob('**/*'))])\n",
    "    files = [datetime.datetime.fromtimestamp(f.stat().st_mtime).strftime('%Y%m%d%H%M%S') for f in files]\n",
    "    if (len(files) == 0): return(None)\n",
    "    return(sha256(str.encode('|'.join(files))).hexdigest())\n",
    "\n",
    "sep = ' <>+0+<> '\n",
    "\n",
    "def indexer(c: Dict, catalog_filename: str, index_filename: str, rackdir: str, sep: str=sep) -> Dict:\n",
    "    'generate index from partial catalog based on catalog.partial.json ordinalities with faults.json support'\n",
    "    faults = []\n",
    "    if Path(rackdir + '/faults.json').exists():\n",
    "        faults = [[m['plugin'], m['version'], m['model']] for m in json.load(open(rackdir + '/faults.json'))]\n",
    "    i = {'sep': sep,\n",
    "         'rackdir': rackdir, 'catalog': catalog_filename, \n",
    "         'timestamp': datetime.datetime.fromtimestamp(Path(f'{rackdir}/{catalog_filename}').stat().st_mtime).strftime('%Y%m%d%H%M%S'),\n",
    "         'plugins': {k['slug']:(i,hash_plugin_files(rackdir+'/plugins/'+k['slug'])) for i,k in enumerate(c['plugins'])},\n",
    "         'modules': {f\"{p['slug']}{sep}{m['slug']}\":(i,hash_plugin_module(p['slug'], p['version'], m['slug'])) for p in c['plugins'] \\\n",
    "                     for i,m in enumerate(p['models'])},\n",
    "         'iterator': [[p['slug'], p['version'], m['slug']] for p in c['plugins'] for m in p['models'] \\\n",
    "                      if not [p['slug'], p['version'], m['slug']] in faults],\n",
    "         'faults': faults,\n",
    "         'pluginCount': len(c['plugins']),\n",
    "         'moduleCount': sum(map(lambda p: p['modelCount'], c['plugins']))}\n",
    "    json.dump(i, open(rackdir + '/' + index_filename, 'w'), indent=2, ensure_ascii=False)\n",
    "    return(i)\n",
    "\n",
    "# try:\n",
    "#     ci = indexer(catalog, 'catalog.json', 'catalog.index.json', rackdir, sep)\n",
    "#     print(f\"generated index on 'catalog.json' as 'catalog.index.json'\")\n",
    "# except: pass\n",
    "# try:\n",
    "#     ci = indexer(catalog_partial, 'catalog.partial.json', 'catalog.partial.index.json', rackdir, sep)\n",
    "#     print(f\"generated index on 'catalog.partial.json' as 'catalog.partial.index.json'\")\n",
    "# except: pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some covience wrapper functions for invoking `DLwigglz r4xh4x` `catalog (partial)` and `patch` buttons using MIDI to trigger keyboard macros. Reference patches are used from the `./patches/_r4xh4x` folder -- update them as underlying modules/Rack evolve. Currently used modules include the following:\n",
    "\n",
    "1. DLwigglz r4xh4x\n",
    "1. Frozen Wasteland SeriouslySlowLFO\n",
    "1. Bogaudio Offset\n",
    "\n",
    "The following plumbing assumes some type of MIDI-to-keyboard utility software (e.g. [Keyboard Maestro](https://www.keyboardmaestro.com/main/), et'al) with the following mappings (MIDI note => behavior/keystroke):\n",
    "\n",
    "1. 69 => CTRL+SHIFT+O (Revert toolbar item hotkey)\n",
    "1. 70 => set focus to Rack from Chrome (assumes it's running)\n",
    "1. 71 => set focus to Chrome from Rack (assumes it's running)\n",
    "\n",
    "This can be refactored as soon as Rack supports an extension API for \"main thread\" features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "code_folding": [
     0,
     10,
     16,
     28,
     45,
     69
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r4xh4x_catalog_partial_wrapper: switching to VCV Rack and cycling _r4xh4x_.vcv\n",
      "  partial catalog generated, see catalog.partial.json\n",
      "generated catalog.partial.index.json from catalog.partial\n",
      "r4xh4x_patch_wrapper: switching to VCV Rack and cycling _r4xh4x_.vcv\n",
      " *** error, rack is not running -- possibly crashed, please investigate\n",
      "  automatic patch generation complete, see patch*.json files\n",
      "\n",
      "110 plugins with 905 modules installed in /Users/dirkleas/Desktop/h4x/_queue_/vcv/Rack\n"
     ]
    }
   ],
   "source": [
    "def serialize(patch, seq=1):\n",
    "    'serialize patch and trigger rack reopen/revert'\n",
    "    json.dump(patch, open(rackdir + '/patches/_r4xh4x_/_r4xh4x_.vcv', 'w'), indent=2, ensure_ascii=False)\n",
    "#     if patch['modules']:\n",
    "    json.dump(patch, open(rackdir + f'/patch{str(seq).zfill(5)}.vcv', 'w'), indent=2, ensure_ascii=False)\n",
    "    sleep(0.5)\n",
    "    mido.open_output().send(mido.Message('note_on', note=69)); sleep(0.25) # trigger revert/reOpen\n",
    "    if os.path.exists(rackdir + '/patch.json'):\n",
    "        os.rename(rackdir + '/patch.json', rackdir + f'/patch{str(seq).zfill(5)}.json')\n",
    "\n",
    "def patch_module(ps, v, ms, pos=[0, 0]):\n",
    "    'generate subpatch module fragment at specified rack position'\n",
    "    module = {'plugin': '', 'version': '', 'model': '', 'pos': [0, 0], 'params': [], 'data': {}} # pos[col,row]\n",
    "    module['plugin'] = ps; module['version'] = v; module['model'] = ms; module['pos'] = copy.deepcopy(pos)\n",
    "    return(module)\n",
    "\n",
    "def r4xh4x_blank_patch(rackdir: str) -> None:\n",
    "    'revert to blank patch via keyboard macro/MIDI'\n",
    "    if not is_running(): # consider starting it if not running...\n",
    "        print(' *** error, rack is not running -- possibly crashed, please investigate')\n",
    "        return\n",
    "    mido.open_output().send(mido.Message('note_on', note=70)); sleep(0.25) # head over to rack\n",
    "    shutil.copy(rackdir + '/patches/_r4xh4x_/_r4xh4x_blank.vcv', \n",
    "                rackdir + '/patches/_r4xh4x_/_r4xh4x_.vcv')\n",
    "    mido.open_output().send(mido.Message('note_on', note=69)); sleep(0.25) # trigger revert/reOpen\n",
    "    mido.open_output().send(mido.Message('note_on', note=71)) # back to chrome\n",
    "# r4xh4x_blank_patch(rackdir)\n",
    "\n",
    "def r4xh4x_catalog_partial_wrapper(rackdir: str) -> None:\n",
    "    'invoke DLwigglz r4xh4x catalog(partial) functionality via keyboard macro/MIDI'\n",
    "    print('r4xh4x_catalog_partial_wrapper: switching to VCV Rack and cycling _r4xh4x_.vcv')\n",
    "    if not is_running(): # consider starting it if not running...\n",
    "        print(' *** error, rack is not running -- possibly crashed, please investigate')\n",
    "        return\n",
    "    mido.open_output().send(mido.Message('note_on', note=70)); sleep(0.25) # head over to rack\n",
    "    shutil.copy(rackdir + '/patches/_r4xh4x_/_r4xh4x_catalog_wrapper.vcv', \n",
    "                rackdir + '/patches/_r4xh4x_/_r4xh4x_.vcv')\n",
    "    mido.open_output().send(mido.Message('note_on', note=69)); sleep(0.25) # trigger revert/reOpen\n",
    "    r4xh4x_blank_patch(rackdir)\n",
    "    print('  partial catalog generated, see catalog.partial.json')\n",
    "    mido.open_output().send(mido.Message('note_on', note=71)) # back to chrome\n",
    "r4xh4x_catalog_partial_wrapper(rackdir)\n",
    "catalog_partial = json.load(open(rackdir + '/catalog.partial.json'))\n",
    "ci = indexer(catalog_partial, 'catalog.partial.json', 'catalog.partial.index.json', rackdir, sep)\n",
    "print('generated catalog.partial.index.json from catalog.partial')\n",
    "\n",
    "# *** VALLEY BLOWS!!! create modules list with just their stuff\n",
    "def r4xh4x_patch_wrapper(modules: List, limit: int=50) -> None:\n",
    "    'invoke DLwigglz r4xh4x \"patch\" on generated modules patch via keyboard macro/midi'\n",
    "    for p in Path(rackdir).glob('patch*.*'): p.unlink() # zap patch files from prior runs\n",
    "    print('r4xh4x_patch_wrapper: switching to VCV Rack and cycling _r4xh4x_.vcv')\n",
    "    if not is_running(): # consider starting it if not running...\n",
    "        print(' *** error, rack is not running -- possibly crashed, please investigate')\n",
    "        return\n",
    "    mido.open_output().send(mido.Message('note_on', note=70)); sleep(0.25) # head over to rack\n",
    "    patch = json.load(open(rackdir + '/patches/_r4xh4x_/_r4xh4x_patch_wrapper.vcv'))\n",
    "    reference_module_count = len(patch['modules']) # always keep reference modules when iterating\n",
    "    idx = 0; seq = 0\n",
    "    for plugin,version,module in modules:\n",
    "        if idx == limit: # better serialize patch\n",
    "            serialize(patch, seq)\n",
    "            del patch['modules'][reference_module_count:] # delete iteration modules\n",
    "            idx = 0; seq += 1\n",
    "        patch['modules'].append(patch_module(plugin, version, module, [0, 1]))\n",
    "        idx += 1\n",
    "    if len(patch['modules']) > reference_module_count: serialize(patch, seq)\n",
    "    r4xh4x_blank_patch(rackdir)\n",
    "    print('  automatic patch generation complete, see patch*.json files')\n",
    "    mido.open_output().send(mido.Message('note_on', note=71)) # back to chrome\n",
    "r4xh4x_patch_wrapper(ci['iterator'])\n",
    "\n",
    "def r4xh4x_patch_exerciser(rackdir: str) -> None:\n",
    "    'qa exerciser to reload existing patch99999.vcv test patches from r4xh4x_patch_wrapper to reproduce segfaults'\n",
    "    print('r4xh4x_patch_exerciser: switching to VCV Rack and cycling _r4xh4x_.vcv')\n",
    "    if not is_running(): # consider starting it if not running...\n",
    "        print(' *** error, rack is not running -- possibly crashed, please investigate')\n",
    "        return\n",
    "    patches = [f\"patch{str(x).zfill(5)}\" for x in range(len(list(Path(rackdir).glob('patch*.vcv')))-1)]\n",
    "    patches = list(map(lambda p: json.load(open(rackdir + f'/{p}.vcv')), patches))\n",
    "    mido.open_output().send(mido.Message('note_on', note=70)); sleep(0.25) # head over to rack\n",
    "    for x in range(3):\n",
    "        for i,p in enumerate(patches):\n",
    "            if not is_running(): # consider starting it if not running...\n",
    "                print(' *** error, rack is not running -- possibly crashed, please investigate')\n",
    "                return\n",
    "            serialize(p, i)\n",
    "    r4xh4x_blank_patch(rackdir)\n",
    "    print('  patch*.json patches exercised')\n",
    "    mido.open_output().send(mido.Message('note_on', note=71)) # back to chrome\n",
    "# r4xh4x_patch_exerciser(rackdir)\n",
    "\n",
    "print(); print(ci['pluginCount'], 'plugins with', ci['moduleCount'], 'modules installed in', rackdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can grab geometry for a given module from it's `r4xhrx patch` serialized output -- still need to figure out whether to keep both `catalog.json` and `catalog.partial.json` around now that we can generate a full `catalog.json` fork-free."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0,
     4
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'data': {'shouldTriggerOnLoad': False, 'triggerOnLoad': True},\n",
      "  'height': 380,\n",
      "  'inputCount': 7,\n",
      "  'outputCount': 8,\n",
      "  'paramCount': 14,\n",
      "  'params': [{'paramId': 0, 'value': 0.0},\n",
      "             {'paramId': 1, 'value': 0.119999997},\n",
      "             {'paramId': 2, 'value': 0.319999993},\n",
      "             {'paramId': 3, 'value': 0.5},\n",
      "             {'paramId': 4, 'value': 0.319999993},\n",
      "             {'paramId': 5, 'value': 0.449999988},\n",
      "             {'paramId': 6, 'value': 1.0},\n",
      "             {'paramId': 7, 'value': 1.0},\n",
      "             {'paramId': 8, 'value': 1.0},\n",
      "             {'paramId': 9, 'value': 0.0},\n",
      "             {'paramId': 10, 'value': 1.0},\n",
      "             {'paramId': 11, 'value': 1.0},\n",
      "             {'paramId': 12, 'value': 1.0},\n",
      "             {'paramId': 13, 'value': 1.0}],\n",
      "  'width': 225}]\n",
      "[('Bogaudio', '0.6.7', 'Bogaudio-DADSRHPlus'),\n",
      " ('Bogaudio', '0.6.7', 'Bogaudio-Noise'),\n",
      " ('Bogaudio', '0.6.7', 'Bogaudio-VCA'),\n",
      " ('Bogaudio', '0.6.7', 'Bogaudio-Switch'),\n",
      " ('Bogaudio', '0.6.7', 'Bogaudio-Reftone'),\n",
      " ('Bogaudio', '0.6.7', 'Bogaudio-VU'),\n",
      " ('Bogaudio', '0.6.7', 'Bogaudio-Offset'),\n",
      " ('Bogaudio', '0.6.7', 'Bogaudio-Mix4'),\n",
      " ('Bogaudio', '0.6.7', 'Bogaudio-Additator'),\n",
      " ('Bogaudio', '0.6.7', 'Bogaudio-Follow'),\n",
      " ('Bogaudio', '0.6.7', 'Bogaudio-VCO'),\n",
      " ('Bogaudio', '0.6.7', 'Bogaudio-Mix8'),\n",
      " ('Bogaudio', '0.6.7', 'Bogaudio-CVD'),\n",
      " ('Bogaudio', '0.6.7', 'Bogaudio-FlipFlop'),\n",
      " ('Bogaudio', '0.6.7', 'Bogaudio-SampleHold'),\n",
      " ('Bogaudio', '0.6.7', 'Bogaudio-Shaper'),\n",
      " ('Bogaudio', '0.6.7', 'Bogaudio-DADSRH'),\n",
      " ('Bogaudio', '0.6.7', 'Bogaudio-Manual'),\n",
      " ('Bogaudio', '0.6.7', 'Bogaudio-Stack'),\n",
      " ('Bogaudio', '0.6.7', 'Bogaudio-Bool'),\n",
      " ('Bogaudio', '0.6.7', 'Bogaudio-Mult'),\n",
      " ('Bogaudio', '0.6.7', 'Bogaudio-Detune'),\n",
      " ('Bogaudio', '0.6.7', 'Bogaudio-Sums'),\n",
      " ('Bogaudio', '0.6.7', 'Bogaudio-FMOp'),\n",
      " ('Bogaudio', '0.6.7', 'Bogaudio-XCO'),\n",
      " ('Bogaudio', '0.6.7', 'Bogaudio-VCM'),\n",
      " ('Bogaudio', '0.6.7', 'Bogaudio-LFO'),\n",
      " ('Bogaudio', '0.6.7', 'Bogaudio-VCAmp'),\n",
      " ('Bogaudio', '0.6.7', 'Bogaudio-EightFO'),\n",
      " ('Bogaudio', '0.6.7', 'Bogaudio-Analyzer'),\n",
      " ('Bogaudio', '0.6.7', 'Bogaudio-DGate'),\n",
      " ('Bogaudio', '0.6.7', 'Bogaudio-XFade'),\n",
      " ('Bogaudio', '0.6.7', 'Bogaudio-ADSR'),\n",
      " ('Bogaudio', '0.6.7', 'Bogaudio-ShaperPlus'),\n",
      " ('Bogaudio', '0.6.7', 'Bogaudio-Pan'),\n",
      " ('Core', '0.6.1', 'QuadMIDIToCVInterface'),\n",
      " ('Core', '0.6.1', 'MIDICCToCVInterface'),\n",
      " ('Core', '0.6.1', 'Notes'),\n",
      " ('Core', '0.6.1', 'MIDIToCVInterface'),\n",
      " ('Core', '0.6.1', 'AudioInterface'),\n",
      " ('Core', '0.6.1', 'Blank'),\n",
      " ('Core', '0.6.1', 'MIDITriggerToCVInterface'),\n",
      " ('DLwigglz', '0.6.2', 'DLwigglz-r4xH4x'),\n",
      " ('FrozenWasteland', '0.6.7', 'SeriouslySlowLFO'),\n",
      " ('squinkylabs-plug1', '0.6.5', 'squinkylabs-booster'),\n",
      " ('squinkylabs-plug1', '0.6.5', 'squinkylabs-freqshifter'),\n",
      " ('squinkylabs-plug1', '0.6.5', 'squinkylabs-vocalfilter'),\n",
      " ('squinkylabs-plug1', '0.6.5', 'squinkylabs-tremolo'),\n",
      " ('squinkylabs-plug1', '0.6.5', 'squinkylabs-coloredNoise'),\n",
      " ('squinkylabs-plug1', '0.6.5', 'squinkylabs-vocalanimator'),\n",
      " ('Valley', '0.6.5', 'uGraph'),\n",
      " ('Valley', '0.6.5', 'Topograph')]\n"
     ]
    }
   ],
   "source": [
    "def patch_modules(patch: Dict) -> List:\n",
    "    'unique sorted list of modules from patch (case insensitive)'\n",
    "    return(sorted(list(set([(m['plugin'], m['version'], m['model']) for m in patch['modules']])), key=lambda s: s[0].lower()))\n",
    "\n",
    "def module_nonpartials_from_patch(ps: str, v: str, ms: str, patch: Dict) -> Dict:\n",
    "    'parse specified module form r4xh4x serialized patch, None if not found'\n",
    "    module = [m for m in patch['modules'] if m['plugin'] == ps and m['version'] == v and m['model'] == ms]\n",
    "    if module: [module[0].pop(k) for k in ['plugin', 'version', 'model', 'pos']]\n",
    "    return(module if len(module) == 1 else None)\n",
    "\n",
    "patch = json.load(open(rackdir + '/patch00000.json'))\n",
    "modules = patch_modules(patch)\n",
    "p,v,m = modules[0]\n",
    "pp(module_nonpartials_from_patch(p, v, m, patch))\n",
    "pp(modules)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
